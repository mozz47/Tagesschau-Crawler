# Tagesschau Web Crawler

Ein einfacher Web Crawler, der Nachrichtenartikel von [Tagesschau.de](https://www.tagesschau.de/) extrahiert, speichert und analysiert.

## Funktionen
- ğŸ“° **Extrahiert Nachrichtenartikel** von Tagesschau.de (Titel, Inhalt, VerÃ¶ffentlichungsdatum und Link).
- ğŸ’¾ **Speichert die gesammelten Daten** in CSV- und TXT-Dateien.
- ğŸ“Š **Analysiert hÃ¤ufige WÃ¶rter** aus den Artikeln und Ãœberschriften.

## Verwendung

1. **Crawlen von Artikeln:**
   ```python
   articles = getArt()
   ```

2. **Speichern der Daten:**
   ```python
   saveToCsv(articles)
   saveToTxt(articles, "TagesschauToTxt.txt")
   ```

3. **HÃ¤ufigste WÃ¶rter im Artikeltext analysieren:**
   ```python
   mostCommonWordsFromTxt("TagesschauToTxt.txt", 100)
   ```

4. **HÃ¤ufigste WÃ¶rter in Ãœberschriften analysieren:**
   ```python
   printMostCommonInHeadline(articles, 100)
   ```

## ğŸ› ï¸ AbhÃ¤ngigkeiten
Das Skript benÃ¶tigt folgende Python-Bibliotheken:
- `requests`
- `BeautifulSoup`
- `collections.Counter`
- `csv`
- `time`


## âš ï¸ Hinweise
- Das Skript pausiert kurz zwischen den Anfragen, um die Server nicht zu Ã¼berlasten.
- Es verarbeitet nur relevante Artikel und filtert unwichtige Links automatisch aus.

---

ğŸ“Œ **Lizenz**: Dieses Projekt dient nur zu Lernzwecken. Bitte beachte die Nutzungsbedingungen von Tagesschau.de.

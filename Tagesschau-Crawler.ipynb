{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28db13ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "from datetime import date\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e781656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CrawledArticle():\n",
    "    def __init__(self, topline, headline, content, link, release):\n",
    "        self.topline = topline\n",
    "        self.headline = headline\n",
    "        self.content = content\n",
    "        self.link = link\n",
    "        self.release = release\n",
    "\n",
    "def printArticles(listOfCrawledArticles):\n",
    "     for article in listOfCrawledArticles:\n",
    "        print(\"------\")\n",
    "        print(article.link)\n",
    "        print(article.topline)\n",
    "        print(article.headline)\n",
    "        print(article.content)\n",
    "        print(\"------\")\n",
    "        \n",
    "def getArt(): #Get all Articles from Tagesschau.de\n",
    "    url = \"https://www.tagesschau.de/\"\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    t = requests.get(url)\n",
    "    site = BeautifulSoup(t.text, \"html.parser\")\n",
    "    \n",
    "    print(\"Getting all Links...\")\n",
    "    listOfCrawledArticles = []\n",
    "    for link in site.find_all('a'):\n",
    "        #Sort out all useless articles\n",
    "        if link.get('href')[0] == \"#\" or link.get('href')[0] != \"h\" or link.get('href')[-4:] != \"html\" or link.parent is None:\n",
    "            continue\n",
    "        elif link.parent.select(\".teaser__topline\") == [] or link.select(\".teaser__headline\")[0].text == \"tagesthemen\" or link.select_one(\".teaser__topline\").text == \"ARD-Programm\":\n",
    "            continue\n",
    "        elif \"tagesschau\" not in link.get('href'):\n",
    "            continue\n",
    "        else:\n",
    "            headline = link.select(\".teaser__headline\")[0].text\n",
    "            linkHref = link.get('href')\n",
    "            topline = link.parent.select(\".teaser__topline\")[0].text\n",
    "            release = #TODO\n",
    "            crawled = CrawledArticle(topline, headline, \"\", linkHref, #TODO Release)\n",
    "            listOfCrawledArticles.append(crawled)\n",
    "            \n",
    "    print(\"Got \" + str(len(listOfCrawledArticles)) + \" articles...\")\n",
    "    getContent(listOfCrawledArticles)\n",
    "    return listOfCrawledArticles\n",
    "\n",
    "def getContent(listOfArticles):\n",
    "    for article in listOfArticles:\n",
    "        print(\"Getting content of article: \" + article.headline)\n",
    "        contentOfArticle = \"\"\n",
    "        URL = article.link\n",
    "        time.sleep(0.2)\n",
    "        t = requests.get(URL)\n",
    "        site = BeautifulSoup(t.text, \"html.parser\")\n",
    "        \n",
    "        for paragraph in site.find_all('p'):\n",
    "            \n",
    "            if bool(paragraph.attrs) is False:\n",
    "                continue\n",
    "            elif paragraph.attrs[\"class\"].count(\"textabsatz\") == 0:\n",
    "                continue\n",
    "            else:\n",
    "                contentOfArticle = contentOfArticle + paragraph.text.strip()\n",
    "                \n",
    "        article.content = contentOfArticle\n",
    "        \n",
    "    print(\"--DONE--\")    \n",
    "    return\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb6bbfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting all Links...\n",
      "Got 1 articles...\n",
      "Getting content of article: Tabubruch Bundestag, Fehlgeburten, TikTok-Blockbuster\n",
      "--DONE--\n",
      "------\n",
      "https://www.tagesschau.de/multimedia/podcast/15-minuten/audio-tabubruch-im-bundestag--schutz-nach-fehlgeburten-100.html\n",
      "15 Minuten\n",
      "Tabubruch Bundestag, Fehlgeburten, TikTok-Blockbuster\n",
      "\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "articles = getArt()\n",
    "printArticles(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f41e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveToCsv(articles):\n",
    "    dateNow = date.today()\n",
    "    fileName = \"TagesschauCrawl\" + str(dateNow) + \".csv\"\n",
    "    with open(fileName, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        articlewriter = csv.writer(csvfile, delimiter=';', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        for article in articles:\n",
    "            articlewriter.writerow([article.topline, article.headline, article.content, article.link])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9b5d2b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'turnTextToOneText' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_58456\\58842474.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mturnTextToOneText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"WholeText\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0msaveToTxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TagesschauToTxt.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'turnTextToOneText' is not defined"
     ]
    }
   ],
   "source": [
    "def saveToTxt(articles, filename):\n",
    "    text = \"\"\n",
    "    for article in articles:\n",
    "        text += str(article.content)\n",
    "    \n",
    "    with open((filename), 'w') as file:\n",
    "        file.write(text)\n",
    "        \n",
    "turnTextToOneText(articles, \"WholeText\")\n",
    "    \n",
    "saveToTxt(articles, \"TagesschauToTxt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6de4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostCommonWordsFromTxt(filename, howManyMostCommonWords):\n",
    "    with open(filename, 'r') as file:\n",
    "        text = file.read()\n",
    "    words = text.split()\n",
    "    wordCounts = Counter(words)\n",
    "    #print(wordCounts)\n",
    "    mostCommonWords = wordCounts.most_common(howManyMostCommonWords)\n",
    "    return mostCommonWords[:howManyMostCommonWords]\n",
    "    \n",
    "mostCommon = mostCommonWordsFromTxt(\"TagesschauToTxt.txt\", 100)\n",
    "for tuple in mostCommon:\n",
    "    if tuple[0].islower() or \"-\" in tuple[0] or \"+\" in tuple[0]:\n",
    "        continue\n",
    "    else: print(tuple)\n",
    "#print(mostCommon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c406e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMostCommonInHeadline(articles, howManyMostCommonWords):   \n",
    "    headlineText = \"\"\n",
    "    for article in articles:\n",
    "        headLine = article.headline.split()\n",
    "        for word in headLine:\n",
    "            if word.islower() or \"+\" in word or \"-\" in word:\n",
    "                continue\n",
    "            else:\n",
    "                if \"?\" in word:\n",
    "                    word = word.replace(\"?\", \"\")\n",
    "                headlineText += word + \" \"\n",
    "\n",
    "    words = headlineText.split()\n",
    "    wordCounts = Counter(words)\n",
    "    mostCommonHeadline = wordCounts.most_common(howManyMostCommonWords)\n",
    "    print(mostCommonHeadline[:howManyMostCommonWords])\n",
    "    \n",
    "printMostCommonInHeadline(articles, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0040fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b459e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
